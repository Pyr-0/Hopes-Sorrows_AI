# ğŸ­ Hopes & Sorrows - Interactive Emotional Voice Analysis

An innovative web application that captures, analyzes, and visualizes human emotions through voice recordings using advanced AI and stunning real-time visualizations.

## âœ¨ What is Hopes & Sorrows?

Hopes & Sorrows is an interactive emotional analysis platform that transforms your voice into beautiful, dynamic visualizations. Speak about your feelings, and watch as AI analyzes your emotions and creates personalized "emotion blobs" that float and interact in a mesmerizing digital landscape.

### ğŸ¯ Key Features

- **ğŸ¤ Real-time Voice Recording**: Capture up to 44 seconds of emotional expression
- **ğŸ¤– Advanced AI Analysis**: Dual sentiment analysis using both transformer models and LLM
- **ğŸ¨ Dynamic Visualizations**: Real-time emotion blobs with physics-based interactions
- **ğŸ“Š Emotion Categories**: Hope, Sorrow, Transformative, Ambivalent, and Reflective emotions
- **ğŸ‘¥ Speaker Identification**: Track multiple speakers across sessions
- **ğŸ“ˆ Analytics Dashboard**: Comprehensive statistics and emotion tracking
- **ğŸŒ Web-based Interface**: No installation required - runs in your browser
- **ğŸ’¾ Persistent Storage**: All analyses saved to SQLite database

### ğŸ­ Emotion Categories

The system classifies emotions into five meaningful categories:

- **ğŸ’š Hope**: Joy, optimism, excitement, love, gratitude
- **ğŸ’™ Sorrow**: Sadness, grief, disappointment, loneliness
- **ğŸŸ¡ Transformative**: Anger, determination, breakthrough moments
- **ğŸŸ  Ambivalent**: Mixed emotions, uncertainty, complexity
- **âšª Reflective**: Contemplation, neutrality, thoughtfulness

### ğŸ§® Advanced Scoring System

Hopes & Sorrows uses a sophisticated multi-dimensional scoring system to capture emotional nuance:

#### Score Components

- **ğŸ“Š Sentiment Score** (`-1.0` to `1.0`): Emotional polarity where negative values represent sorrow-leaning emotions and positive values represent hope-leaning emotions
- **âš¡ Intensity Score** (`0.0` to `1.0`): Emotional strength - how powerful the emotion is regardless of polarity
- **ğŸ¯ Confidence Score** (`0.0` to `1.0`): AI certainty in the classification - how confident the system is about its analysis

#### Blob Size Calculation

Emotion blobs are dynamically sized based on emotional properties:

```
Final Size = Base Size (10px) + 
            Intensity Ã— 12 + 
            Confidence Ã— 6 + 
            |Score| Ã— 8
```

**Size Hierarchy**: Intensity > Confidence > Absolute Score Value  
**Size Range**: 8px to 30px for optimal visual balance

### ğŸ”¬ Physics-Based Behavior System

Each emotion blob exhibits realistic physics behavior that reflects psychological principles:

#### Movement Mechanics

1. **ğŸŒŠ Organic Floating**: Sine/cosine wave patterns scaled by emotional energy
2. **âš–ï¸ Gravitational Forces**: Hope naturally rises (â†‘), sorrow naturally falls (â†“)
3. **ğŸ¤ Social Dynamics**: Emotions attract/repel based on psychological compatibility
4. **ğŸ’¥ Collision Physics**: Mass-based elastic collisions with proper impulse calculation
5. **ğŸ›¡ï¸ Boundary Forces**: Gentle containment to keep emotions visible
6. **ğŸŒŠ Wave Reactions**: Collective response when new emotions appear

#### Behavioral Personalities

Each emotion category has distinct social tendencies:

- **Hope** (0.7): Seeks companionship, creates positive social energy
- **Transformative** (0.5): Moderate social interaction, focused energy
- **Ambivalent** (0.1): Uncertain about social contact, hesitant movement
- **Reflective** (-0.1): Prefers contemplative solitude
- **Sorrow** (-0.3): Seeks gentle comfort but maintains distance

#### Mass & Physics Properties

- **Mass Calculation**: `(Base Size Ã· 10) + Intensity Ã— 2 + |Score| Ã— 1.5`
- **Velocity Limits**: 3px/frame maximum to prevent chaotic movement
- **Collision Response**: Larger emotions have more inertia, smaller emotions bounce more
- **Social Range**: 200px interaction radius for emotional influence

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+ (use `python3` command)
- AssemblyAI API key (free tier available)
- Modern web browser with microphone access

### 1. Clone and Setup

```bash
git clone <repository-url>
cd AI/Final_Project
```

### 2. Install Dependencies

```bash
pip3 install -r requirements.txt
```

### 3. Complete Setup

Use the automated setup:

```bash
make setup
```

Or manual setup:

```bash
# Copy environment template
cp env.template .env
# Edit .env with your API keys

# Install dependencies  
make install

# Initialize database
make setup-db
```

**Required API Keys:**

1. **AssemblyAI API Key** (Required for audio transcription):
   - Sign up at [https://www.assemblyai.com/](https://www.assemblyai.com/)
   - Get your free API key from the dashboard
   - Add to `.env`: `ASSEMBLYAI_API_KEY=your_key_here`

2. **OpenAI API Key** (Optional for enhanced LLM analysis):
   - Sign up at [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
   - Get your API key (requires payment setup)
   - Add to `.env`: `OPENAI_API_KEY=your_key_here`

**âš ï¸ Note**: Without the AssemblyAI API key, audio recording features won't work, but text-based sentiment analysis will still function perfectly.

### 4. Launch the Application

```bash
# Using make (recommended)
make run-web

# Or using main entry point
python3 main.py web

# Or using direct script
python3 scripts/run_web.py
```

### 5. Open in Browser

Navigate to: `http://localhost:8080`

## ğŸ® How to Use

1. **ğŸ  Landing Page**: Learn about the project and its emotional categories
2. **ğŸ¤ Main App** (`/app`): 
   - Click the record button to capture your voice
   - Speak naturally about your emotions (up to 44 seconds)
   - Watch as AI analyzes your speech and creates emotion blobs
   - Interact with the visualization - blobs respond to mouse movement
   - Use the side panel to filter emotions by category
3. **ğŸ“Š Statistics** (`/stats`): View your emotional journey over time
4. **â„¹ï¸ Info** (`/info`): Detailed information about the technology

## ğŸ—ï¸ Project Architecture

```
hopes-sorrows/
â”œâ”€â”€ ğŸ“ src/hopes_sorrows/           # Main source code (Python package)
â”‚   â”œâ”€â”€ ğŸ“ core/                    # Core utilities and configuration
â”‚   â”œâ”€â”€ ğŸ“ analysis/                # AI analysis modules
â”‚   â”‚   â”œâ”€â”€ ğŸ“ sentiment/           # Sentiment analysis components
â”‚   â”‚   â””â”€â”€ ğŸ“ audio/               # Audio processing components
â”‚   â”œâ”€â”€ ğŸ“ data/                    # Data models and database management
â”‚   â”œâ”€â”€ ğŸ“ web/                     # Web application
â”‚   â”‚   â”œâ”€â”€ ğŸ“ api/                 # Flask API endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ“ static/              # CSS, JS, images
â”‚   â”‚   â””â”€â”€ ğŸ“ templates/           # HTML templates
â”‚   â””â”€â”€ ğŸ“ cli/                     # Command-line interface
â”œâ”€â”€ ğŸ“ data/                        # Application data (gitignored)
â”‚   â”œâ”€â”€ ğŸ“ databases/               # SQLite databases
â”‚   â”œâ”€â”€ ğŸ“ recordings/              # Audio recordings
â”‚   â””â”€â”€ ğŸ“ uploads/                 # File uploads
â”œâ”€â”€ ğŸ“ scripts/                     # Standalone scripts and utilities
â”œâ”€â”€ ğŸ“ tests/                       # Test suites
â”œâ”€â”€ ğŸ“ docs/                        # Documentation
â”œâ”€â”€ ğŸ“„ main.py                      # Main entry point
â”œâ”€â”€ ğŸ“„ setup.py                     # Package installation script
â”œâ”€â”€ ğŸ“„ Makefile                     # Development automation
â””â”€â”€ ğŸ“„ requirements.txt             # Python dependencies
```

**ğŸ“– See [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) for detailed structure documentation.**

## ğŸ”§ Technology Stack

### Backend
- **[Flask](https://flask.palletsprojects.com/)**: Web framework with WebSocket support
- **[AssemblyAI](https://www.assemblyai.com/)**: Speech-to-text transcription and speaker diarization
- **[Hugging Face Transformers](https://huggingface.co/transformers/)**: AI model library
  - **Model Used**: [`j-hartmann/emotion-english-distilroberta-base`](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base) - DistilRoBERTa fine-tuned for emotion classification
- **[OpenAI GPT](https://openai.com/api/)**: Advanced emotional understanding and reasoning
- **[SQLAlchemy](https://www.sqlalchemy.org/)**: Database ORM
- **SQLite**: Local data storage

### Frontend
- **Vanilla JavaScript**: Core application logic
- **[P5.js](https://p5js.org/)**: Creative coding and emotion blob visualizations
- **Canvas 2D API**: Background particle effects and gradients
- **[Anime.js](https://animejs.com/)**: Smooth animations and transitions
- **[Socket.IO](https://socket.io/)**: Real-time WebSocket communication
- **[WebAudio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)**: Microphone access and recording

### AI & Analysis
- **Speaker Diarization**: Multi-speaker identification via AssemblyAI
- **Emotion Classification**: 7-emotion model (anger, disgust, fear, joy, neutral, sadness, surprise)
- **Sentiment Scoring**: Custom hope/sorrow mapping algorithm
- **Confidence Scoring**: Analysis reliability metrics
- **Dual Analysis**: Transformer + LLM validation and cross-referencing

## ğŸ“š Documentation

For detailed technical documentation and comprehensive guides, see the [`docs/`](docs/) directory:

- **[Documentation Index](docs/README.md)** - Complete documentation overview and navigation guide
- **[Technical Glossary](docs/GLOSSARY.md)** - Comprehensive guide to all terminology and concepts

## ğŸ—„ï¸ Database Schema

### Tables

**Speakers**: User identification and tracking
- `id`: Unique speaker identifier
- `name`: Speaker name/label
- `created_at`: First appearance
- `last_seen`: Most recent activity

**Transcriptions**: Speech-to-text results
- `id`: Unique transcription ID
- `speaker_id`: Reference to speaker
- `text`: Transcribed speech content
- `confidence`: Transcription accuracy
- `timestamp`: Recording time

**SentimentAnalyses**: Emotional analysis results
- `id`: Analysis identifier
- `transcription_id`: Reference to transcription
- `analyzer_type`: TRANSFORMER or LLM
- `category`: Emotion category (hope, sorrow, etc.)
- `label`: Specific emotion label
- `score`: Sentiment intensity (-1 to 1)
- `confidence`: Analysis confidence (0 to 1)
- `explanation`: AI reasoning (LLM only)

## ğŸ¨ Visualization Features

### Emotion Blobs
- **Physics-based movement**: Blobs float with realistic physics
- **Mouse interaction**: Blobs are attracted to cursor movement
- **Color coding**: Each emotion category has distinct colors
- **Size variation**: Intensity affects blob size
- **Transparency**: Confidence affects opacity

### Real-time Effects
- **Recording waves**: Animated circles during voice capture
- **New blob highlights**: Temporary glow for fresh emotions
- **Pulse animations**: Record button feedback
- **Smooth transitions**: Anime.js powered animations

## ğŸ” API Endpoints

- `GET /`: Landing page
- `GET /app`: Main application
- `GET /stats`: Analytics dashboard
- `GET /info`: Information page
- `GET /api/get_all_blobs`: Retrieve all emotion data
- `POST /upload_audio`: Process voice recordings
- `DELETE /api/clear_visualization`: Reset visualization

## ğŸ› ï¸ Development

### Running in Development Mode

```bash
# Use the dedicated script (port 8080)
python3 scripts/run_web.py

# Or use the main entry point
python3 main.py web
```

### Environment Variables

```bash
FLASK_ENV=development          # Enable debug mode
ASSEMBLYAI_API_KEY=required    # Speech transcription
OPENAI_API_KEY=optional        # Enhanced LLM analysis
```

### Testing

The application includes diagnostic tools:
- `/diagnostic`: System health checks
- `/debug`: Visualization debugging
- Browser console: Detailed logging

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **[AssemblyAI](https://www.assemblyai.com/)**: Speech-to-text transcription and speaker diarization
- **[Hugging Face](https://huggingface.co/)**: Transformer models and AI infrastructure
- **[j-hartmann](https://huggingface.co/j-hartmann)**: Creator of the emotion classification model
- **[OpenAI](https://openai.com/)**: GPT-based sentiment analysis and reasoning
- **[P5.js Community](https://p5js.org/community/)**: Creative coding framework and inspiration
- **[Anime.js](https://animejs.com/)**: Smooth animation library
- **[Flask Community](https://flask.palletsprojects.com/)**: Web framework and ecosystem

## ğŸ†˜ Troubleshooting

### Common Issues

**"python command not found"**
```bash
# Use python3 instead
python3 scripts/run_web.py
```

**Microphone not working**
- Ensure browser has microphone permissions
- Check system audio settings
- Try a different browser (Chrome recommended)

**API Key errors**
- Verify `.env` file exists in project root
- Check API key format and validity
- Restart Flask server after adding keys

**Database errors**
```bash
# Reinitialize database
python3 -c "from database.db_manager import DatabaseManager; DatabaseManager().init_db()"
```

For more help, check the diagnostic page at `/diagnostic` when the server is running.

---

**Transform your voice into art. Discover the emotions within.** ğŸ­âœ¨ 