#!/usr/bin/env python3
"""
Test script to demonstrate the profanity classification fix.
Shows that filtered content is now correctly classified as SORROW instead of HOPE.
"""

import sys
import os
sys.path.append('.')

from sentiment_analysis.sa_transformers import analyze_sentiment, reset_analyzer
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich import box

console = Console()

def test_profanity_classification_fix():
    """Test that profanity content is correctly classified after the fix."""
    console.print("[bold green]üß™ Testing Profanity Classification Fix[/bold green]\n")
    
    # Reset analyzer to ensure clean state
    reset_analyzer()
    
    test_cases = [
        {
            "text": "Sex p***. Stupid bestiality.",
            "description": "Filtered profanity (original issue)",
            "expected_category": "sorrow",
            "expected_not": "hope"
        },
        {
            "text": "This is f*** terrible",
            "description": "Negative sentiment with profanity",
            "expected_category": "sorrow",
            "expected_not": "hope"
        },
        {
            "text": "I love this s***",
            "description": "Positive sentiment with profanity",
            "expected_category": "reflective_neutral",  # Filtered content overrides positive
            "expected_not": "hope"
        },
        {
            "text": "What the h*** is happening",
            "description": "Neutral sentiment with profanity",
            "expected_category": "sorrow",  # Negative sentiment + filtered content
            "expected_not": "hope"
        },
        {
            "text": "I am very happy today",
            "description": "Clean positive content",
            "expected_category": "hope",
            "expected_not": "sorrow"
        },
        {
            "text": "I am very sad today",
            "description": "Clean negative content",
            "expected_category": "sorrow",
            "expected_not": "hope"
        },
        {
            "text": "tick tock tick tock la la la",
            "description": "Nonsensical content",
            "expected_category": "reflective_neutral",
            "expected_not": "hope"
        }
    ]
    
    results_table = Table(box=box.ROUNDED, show_header=True, header_style="bold magenta")
    results_table.add_column("üî§ Input", style="cyan", width=30)
    results_table.add_column("üìù Description", style="yellow", width=25)
    results_table.add_column("üìä Category", style="green", width=15)
    results_table.add_column("üéØ Confidence", style="blue", width=12)
    results_table.add_column("‚úÖ Status", style="white", width=15)
    
    all_passed = True
    
    for case in test_cases:
        try:
            result = analyze_sentiment(case["text"], verbose=False)
            category = result['category']
            confidence = f"{result['confidence']:.1%}"
            score = result['score']
            
            # Check if classification meets expectations
            if category == case["expected_category"]:
                status = "[green]‚úÖ PASS[/green]"
            elif category == case["expected_not"]:
                status = "[red]‚ùå FAIL[/red]"
                all_passed = False
            else:
                status = "[yellow]‚ö†Ô∏è UNEXPECTED[/yellow]"
            
            results_table.add_row(
                f'"{case["text"][:25]}..."' if len(case["text"]) > 25 else f'"{case["text"]}"',
                case["description"],
                category.upper(),
                confidence,
                status
            )
            
        except Exception as e:
            results_table.add_row(
                f'"{case["text"][:25]}..."',
                case["description"],
                "ERROR",
                "N/A",
                f"[red]‚ùå ERROR[/red]"
            )
            all_passed = False
    
    console.print(results_table)
    
    # Summary
    if all_passed:
        console.print(f"\n[bold green]üéâ ALL TESTS PASSED![/bold green]")
        console.print(f"[green]‚úÖ Profanity content is correctly classified as SORROW[/green]")
        console.print(f"[green]‚úÖ Clean positive content is correctly classified as HOPE[/green]")
        console.print(f"[green]‚úÖ Clean negative content is correctly classified as SORROW[/green]")
        console.print(f"[green]‚úÖ Nonsensical content is correctly classified as REFLECTIVE_NEUTRAL[/green]")
    else:
        console.print(f"\n[bold red]‚ùå SOME TESTS FAILED[/bold red]")
        console.print(f"[red]Please review the classification logic[/red]")

def test_before_after_comparison():
    """Show the before/after comparison for the original issue."""
    console.print(f"\n[bold blue]üìä Before/After Comparison[/bold blue]\n")
    
    original_issue_text = "Sex p***. Stupid bestiality."
    result = analyze_sentiment(original_issue_text, verbose=False)
    
    comparison_panel = Panel(
        f"[bold]Original Issue Text:[/bold] \"{original_issue_text}\"\n\n"
        f"[bold red]BEFORE (Bug):[/bold red]\n"
        f"‚Ä¢ Category: HOPE (incorrect)\n"
        f"‚Ä¢ Reason: No patterns detected, defaulted to first category\n"
        f"‚Ä¢ Sentiment Score: {result['score']:.2f} (strongly negative)\n"
        f"‚Ä¢ Problem: Negative sentiment + profanity classified as hope\n\n"
        f"[bold green]AFTER (Fixed):[/bold green]\n"
        f"‚Ä¢ Category: {result['category'].upper()} (correct)\n"
        f"‚Ä¢ Confidence: {result['confidence']:.1%}\n"
        f"‚Ä¢ Sentiment Score: {result['score']:.2f} (strongly negative)\n"
        f"‚Ä¢ Solution: Filtered content detection + sentiment-based fallback\n"
        f"‚Ä¢ Explanation: {result['explanation'][:100]}...",
        title="üîß Fix Demonstration",
        border_style="green",
        padding=(1, 2)
    )
    console.print(comparison_panel)

def main():
    """Run all profanity classification tests."""
    console.print("[bold magenta]üöÄ PROFANITY CLASSIFICATION FIX TESTING[/bold magenta]")
    console.print("="*70)
    
    test_profanity_classification_fix()
    test_before_after_comparison()
    
    console.print(f"\n[bold blue]üìã Summary of Fixes Applied:[/bold blue]")
    
    fixes_summary = Panel(
        "[bold]‚úÖ Fix 1: Sentiment-Based Fallback[/bold]\n"
        "‚Ä¢ When no patterns detected, use sentiment score to set base categories\n"
        "‚Ä¢ Negative sentiment (-0.5 or lower) ‚Üí SORROW (0.8) + REFLECTIVE_NEUTRAL (0.2)\n"
        "‚Ä¢ Positive sentiment (+0.5 or higher) ‚Üí HOPE (0.8) + REFLECTIVE_NEUTRAL (0.2)\n\n"
        "[bold]‚úÖ Fix 2: Filtered Content Detection[/bold]\n"
        "‚Ä¢ Detect asterisks (*) indicating AssemblyAI content filtering\n"
        "‚Ä¢ Negative sentiment + filtered content ‚Üí Boost SORROW, penalize HOPE\n"
        "‚Ä¢ Neutral sentiment + filtered content ‚Üí Boost REFLECTIVE_NEUTRAL, penalize HOPE\n\n"
        "[bold]‚úÖ Fix 3: Nonsensical Content Detection[/bold]\n"
        "‚Ä¢ Fixed regex pattern to avoid false positives on normal sentences\n"
        "‚Ä¢ Only flag truly nonsensical patterns (single letters, excessive repetition)\n"
        "‚Ä¢ Nonsensical content ‚Üí REFLECTIVE_NEUTRAL with low confidence\n\n"
        "[bold]‚úÖ Fix 4: Enhanced Explanations[/bold]\n"
        "‚Ä¢ Added note when filtered content is detected\n"
        "‚Ä¢ Clear explanation of why classification was chosen",
        title="üõ†Ô∏è Applied Fixes",
        border_style="blue",
        padding=(1, 2)
    )
    console.print(fixes_summary)

if __name__ == "__main__":
    main() 